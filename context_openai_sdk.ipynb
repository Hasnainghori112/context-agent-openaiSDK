{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyON/C39dl5cvBbmChX4/NcB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hasnainghori112/context-agent-openaiSDK/blob/main/context_openai_sdk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1Zk7sDjuuVd",
        "outputId": "c68f0ee0-20c6-49c6-d24c-9832d2125320"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/116.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.9/116.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/129.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m129.3/129.3 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/119.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.5/119.5 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/44.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -Uq openai-agents"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from agents import Agent, Runner,  ItemHelpers,AsyncOpenAI, OpenAIChatCompletionsModel , function_tool , RunContextWrapper\n",
        "from agents.run import RunConfig\n",
        "from google.colab import userdata\n",
        "from dataclasses import dataclass\n",
        "import asyncio\n",
        "from agents import (\n",
        "    set_default_openai_api,\n",
        "    set_default_openai_client,\n",
        "    set_tracing_disabled,\n",
        ")\n",
        "\n",
        "gemini_api_key = userdata.get(\"GOOGLE_API_KEY\")\n",
        "\n",
        "\n",
        "# Check if the API key is present; if not, raise an error\n",
        "if not gemini_api_key:\n",
        "    raise ValueError(\"GEMINI_API_KEY is not set. Please ensure it is defined in your .env file.\")\n",
        "\n",
        "#Reference: https://ai.google.dev/gemini-api/docs/openai\n",
        "external_client = AsyncOpenAI(\n",
        "    api_key=gemini_api_key,\n",
        "    base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\",\n",
        ")\n",
        "\n",
        "model = OpenAIChatCompletionsModel(\n",
        "    model=\"gemini-2.0-flash\",\n",
        "    openai_client=external_client\n",
        ")\n",
        "\n",
        "set_default_openai_client(client=external_client, use_for_tracing=False)\n",
        "set_default_openai_api(\"chat_completions\")\n",
        "set_tracing_disabled(disabled=True)"
      ],
      "metadata": {
        "id": "I-5k4C6MyU4B"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai.types.responses import ResponseTextDeltaEvent\n",
        "@dataclass\n",
        "class UserInfo():\n",
        "  name : str\n",
        "  age : int\n",
        "  gender : str\n",
        "  country : str\n",
        "\n",
        "\n",
        "@function_tool\n",
        "async def fatch_user_name(wrapper : RunContextWrapper):\n",
        "  return f\"The user name is {wrapper.context.name}\"\n",
        "\n",
        "@function_tool\n",
        "async def fatch_user_age(wrapper : RunContextWrapper):\n",
        "  return f\"The user age is {wrapper.context.age}\"\n",
        "@function_tool\n",
        "async def fatch_user_gender(wrapper : RunContextWrapper):\n",
        "  return f\"The user gender is {wrapper.context.gender}\"\n",
        "\n",
        "@function_tool\n",
        "async def fatch_user_country(wrapper : RunContextWrapper):\n",
        "  return f\"The user country is {wrapper.context.country}\"\n",
        "\n",
        "user_info = UserInfo(\n",
        "    name = \"Muhammad Hasnain Ghori\",\n",
        "    age = 17,\n",
        "    gender = \"Male\",\n",
        "    country = \"Pakistan\"\n",
        ")\n",
        "assistan = Agent[UserInfo](\n",
        "    name = \"assistant\",\n",
        "    instructions =\"\"\"You are a helpful assistant. Your job is to gather all user details one by one by calling appropriate tools.\n",
        "    Use only one tool at a time,with catchy style\"\"\",\n",
        "    model=model,\n",
        "    tools=[\n",
        "        fatch_user_name,\n",
        "        fatch_user_age,\n",
        "        fatch_user_gender,\n",
        "        fatch_user_country\n",
        "    ],\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "async def main():\n",
        "  result = Runner.run_streamed(assistan , \"please provide all about user info\",context=user_info)\n",
        "  async for event in result.stream_events():\n",
        "    if event.type == \"raw_response_event\" and isinstance(event.data,ResponseTextDeltaEvent):\n",
        "      print(event.data.delta , end=\"\" , flush=True)\n",
        "\n",
        "asyncio.run(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVTTdT5cyrWV",
        "outputId": "6e0c553a-bdbd-488b-f26d-ed2a688bcaa8"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Alright, let's start gathering user information. First, I'll need the user's name.\n",
            "Okay, I've got the user's name. It's Muhammad Hasnain Ghori. Now, let's move on to the next piece of information. How about the user's age?\n",
            "Great! The user is 17 years old. Now that we have the name and age, let's find out the user's gender.\n",
            "Got it! The user is male. Just one more piece of information to complete the profile. Let's get the user's country.\n",
            "Excellent! I have gathered all the user information. The user's name is Muhammad Hasnain Ghori, he is 17 years old, male, and from Pakistan.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai.types.responses import ResponseTextDeltaEvent\n",
        "@dataclass\n",
        "class UserInfo():\n",
        "  name : str\n",
        "  age : int\n",
        "  gender : str\n",
        "  country : str\n",
        "\n",
        "\n",
        "@function_tool\n",
        "async def fatch_user_name(wrapper : RunContextWrapper):\n",
        "  return f\"The user name is {wrapper.context.name}\"\n",
        "\n",
        "@function_tool\n",
        "async def fatch_user_age(wrapper : RunContextWrapper):\n",
        "  return f\"The user age is {wrapper.context.age}\"\n",
        "@function_tool\n",
        "async def fatch_user_gender(wrapper : RunContextWrapper):\n",
        "  return f\"The user gender is {wrapper.context.gender}\"\n",
        "\n",
        "@function_tool\n",
        "async def fatch_user_country(wrapper : RunContextWrapper):\n",
        "  return f\"The user country is {wrapper.context.country}\"\n",
        "\n",
        "user_info = UserInfo(\n",
        "    name = \"MUhammad Hasnain Ghori\",\n",
        "    age = 17,\n",
        "    gender = \"Male\",\n",
        "    country = \"Pakistan\"\n",
        ")\n",
        "assistan = Agent[UserInfo](\n",
        "    name = \"assistant\",\n",
        "    instructions =\"\"\"You are a helpful assistant. Your job is to gather all user details one by one by calling appropriate tools.\n",
        "    Use only one tool at a time,with catchy style\"\"\",\n",
        "    model=model,\n",
        "    tools=[\n",
        "        fatch_user_name,\n",
        "        fatch_user_age,\n",
        "        fatch_user_gender,\n",
        "        fatch_user_country\n",
        "    ],\n",
        "\n",
        ")\n",
        "\n",
        "\n",
        "async def main():\n",
        "  result = Runner.run_streamed(assistan , \"please provide all about user info\",context=user_info)\n",
        "  async for event in result.stream_events():\n",
        "    # print(event)\n",
        "    if event.type == \"raw_response_event\":\n",
        "      continue\n",
        "    elif event.type == \"agent_updated_stream_event\":\n",
        "      print(f\"agent name : {event.new_agent.name}\")\n",
        "      continue\n",
        "    elif event.type == \"run_item_stream_event\":\n",
        "      if event.item.type == \"tool_call_item\":\n",
        "        tool_name = event.item.raw_item.name\n",
        "        print(f\"Tool was called: {tool_name}\")\n",
        "      elif event.item.type == \"tool_call_output_item\":\n",
        "        print(f\"TOOl OUTPUT = {event.item.output}\")\n",
        "      elif event.item.type == \"message_output_item\":\n",
        "         print(f\"-- Message output:\\n {ItemHelpers.text_message_output(event.item)}\" )\n",
        "      else:\n",
        "        pass\n",
        "\n",
        "asyncio.run(main())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TrWjKSMf6LXk",
        "outputId": "80a7af2d-6dd4-421a-aaea-580af7b034f8"
      },
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "agent name : assistant\n",
            "-- Message output:\n",
            " Alright, let's start gathering user details one piece at a time. To begin, I'll need to know the user's name.\n",
            "\n",
            "\n",
            "-- Tool was called: fatch_user_name\n",
            "TOOl OUTPUT = The user name is John\n",
            "-- Message output:\n",
            " Fantastic! The user's name is John. Next up, let's find out the user's age.\n",
            "\n",
            "\n",
            "-- Tool was called: fatch_user_age\n",
            "TOOl OUTPUT = The user age is 25\n",
            "-- Message output:\n",
            " Great! We know John is 25 years old. Now, let's discover John's gender.\n",
            "\n",
            "\n",
            "-- Tool was called: fatch_user_gender\n",
            "TOOl OUTPUT = The user gender is Male\n",
            "-- Message output:\n",
            " Roger that! John is a male. Just one more detail to uncover: John's country.\n",
            "\n",
            "\n",
            "-- Tool was called: fatch_user_country\n",
            "TOOl OUTPUT = The user country is USA\n",
            "-- Message output:\n",
            " Perfect! We've gathered all the info. The user, John, is a 25-year-old male from the USA.\n",
            "\n"
          ]
        }
      ]
    }
  ]
}